{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# Ruta al archivo ZIP\n",
        "zip_path = 'face_dataset.zip'\n",
        "extract_dir = 'face_dataset'\n",
        "\n",
        "# Extraer el contenido del ZIP\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "# Directorios para las carpetas de entrenamiento y prueba\n",
        "train_dir = os.path.join(extract_dir, 'train')\n",
        "test_dir = os.path.join(extract_dir, 'test')\n",
        "\n",
        "# Función para cargar y preprocesar imágenes\n",
        "def load_and_preprocess_images(image_dir, target_size=(128, 128)):\n",
        "    images = []\n",
        "\n",
        "    for filename in os.listdir(image_dir):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "            img_path = os.path.join(image_dir, filename)\n",
        "            img = load_img(img_path, color_mode='grayscale', target_size=target_size)  # Escala de grises y cambiar tamaño\n",
        "            img_array = img_to_array(img) / 255.0  # Convertir a array y normalizar\n",
        "            images.append(img_array)\n",
        "\n",
        "    return np.array(images)\n",
        "\n",
        "# Cargar y preprocesar las imágenes de entrenamiento y prueba\n",
        "X_train = load_and_preprocess_images(train_dir)\n",
        "X_test = load_and_preprocess_images(test_dir)\n",
        "\n",
        "# Aplanar las imágenes para los autoencoders\n",
        "X_train = X_train.reshape((X_train.shape[0], 128 * 128))\n",
        "X_test = X_test.reshape((X_test.shape[0], 128 * 128))\n",
        "\n",
        "# Imprimir las formas de X_train y X_test para confirmar\n",
        "print(\"Nueva forma de X_train:\", X_train.shape)  # Debe ser (num_images, 16384)\n",
        "print(\"Nueva forma de X_test:\", X_test.shape)    # Debe ser (num_images, 16384)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dF6ym716f2XF",
        "outputId": "e327bf15-064e-4f02-eb61-28610d35b8f0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nueva forma de X_train: (200, 16384)\n",
            "Nueva forma de X_test: (12, 16384)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.regularizers import l1\n",
        "import tensorflow as tf\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import seaborn as sns\n",
        "\n",
        "# Funciones de carga y preprocesamiento de datos\n",
        "def load_and_preprocess_data(train_csv_path, test_csv_path):\n",
        "    \"\"\"Carga y preprocesa los datos de los archivos CSV\"\"\"\n",
        "    train_df = pd.read_csv(train_csv_path)\n",
        "    test_df = pd.read_csv(test_csv_path)\n",
        "\n",
        "    # Crear LabelEncoder para las emociones\n",
        "    label_encoder = LabelEncoder()\n",
        "    train_df['emotion_encoded'] = label_encoder.fit_transform(train_df['emotion'])\n",
        "    test_df['emotion_encoded'] = label_encoder.transform(test_df['emotion'])\n",
        "\n",
        "    return train_df, test_df, label_encoder\n",
        "\n",
        "def load_images_from_paths(df, target_size=(128, 128)):\n",
        "    \"\"\"Carga y preprocesa las imágenes desde las rutas especificadas\"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "    encoded_labels = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        try:\n",
        "            img_path = row['path']\n",
        "            img = load_img(img_path, color_mode='grayscale', target_size=target_size)\n",
        "            img_array = img_to_array(img) / 255.0\n",
        "            images.append(img_array)\n",
        "            labels.append(row['emotion'])\n",
        "            encoded_labels.append(row['emotion_encoded'])\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {img_path}: {e}\")\n",
        "            continue\n",
        "\n",
        "    return (np.array(images),\n",
        "            np.array(labels),\n",
        "            np.array(encoded_labels))\n",
        "\n",
        "# Funciones de construcción de modelos\n",
        "def build_sparse_autoencoder(input_dim, encoding_dim, sparsity_reg):\n",
        "    \"\"\"Construye un autoencoder sparse con regularización L1\"\"\"\n",
        "    input_layer = Input(shape=(input_dim,))\n",
        "    encoder = Dense(encoding_dim, activation='relu',\n",
        "                   activity_regularizer=l1(sparsity_reg),\n",
        "                   name='encoder_output')(input_layer)\n",
        "    decoder = Dense(input_dim, activation='sigmoid')(encoder)\n",
        "\n",
        "    autoencoder = Model(input_layer, decoder)\n",
        "    autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    return autoencoder\n",
        "\n",
        "def build_denoising_autoencoder(input_dim, encoding_dim, dropout_rate):\n",
        "    \"\"\"Construye un autoencoder denoising con dropout\"\"\"\n",
        "    input_layer = Input(shape=(input_dim,))\n",
        "    dropout = Dropout(dropout_rate)(input_layer)\n",
        "    encoder = Dense(encoding_dim, activation='relu',\n",
        "                   name='encoder_output')(dropout)\n",
        "    decoder = Dense(input_dim, activation='sigmoid')(encoder)\n",
        "\n",
        "    autoencoder = Model(input_layer, decoder)\n",
        "    autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    return autoencoder\n",
        "\n",
        "# Funciones de entrenamiento y evaluación\n",
        "def train_autoencoder(autoencoder, X_train, epochs=100, batch_size=32):\n",
        "    \"\"\"Entrena el autoencoder con early stopping\"\"\"\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=5,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    history = autoencoder.fit(\n",
        "        X_train, X_train,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        validation_split=0.2,\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return autoencoder, history\n",
        "\n",
        "def get_latent_space(autoencoder, X_data, batch_size=32):\n",
        "    \"\"\"Obtiene el espacio latente del autoencoder\"\"\"\n",
        "    encoder = Model(inputs=autoencoder.input,\n",
        "                   outputs=autoencoder.get_layer('encoder_output').output)\n",
        "    return encoder.predict(X_data, batch_size=batch_size)\n",
        "\n",
        "def train_and_evaluate_classifier(latent_train, latent_test, y_train, y_test):\n",
        "    \"\"\"Entrena y evalúa el clasificador Naive Bayes\"\"\"\n",
        "    classifier = GaussianNB()  # Usamos GaussianNB en lugar de SVC\n",
        "    classifier.fit(latent_train, y_train)\n",
        "\n",
        "    y_pred = classifier.predict(latent_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    return {\n",
        "        'classifier': classifier,\n",
        "        'accuracy': accuracy,\n",
        "        'predictions': y_pred,\n",
        "        'report': classification_report(y_test, y_pred, output_dict=True)\n",
        "    }\n",
        "\n",
        "def train_and_evaluate_classifier_SVC(latent_train, latent_test, y_train, y_test):\n",
        "    \"\"\"Entrena y evalúa el clasificador SVM\"\"\"\n",
        "    classifier = SVC(kernel='rbf', C=1.0)\n",
        "    classifier.fit(latent_train, y_train)\n",
        "\n",
        "    y_pred = classifier.predict(latent_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    return {\n",
        "        'classifier': classifier,\n",
        "        'accuracy': accuracy,\n",
        "        'predictions': y_pred,\n",
        "        'report': classification_report(y_test, y_pred, output_dict=True)\n",
        "    }\n",
        "\n",
        "# Funciones de visualización\n",
        "def plot_training_history(history, title):\n",
        "    \"\"\"Visualiza el historial de entrenamiento\"\"\"\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title(f'Training History - {title}')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "def visualize_latent_space(latent_space, labels, label_encoder, title):\n",
        "    \"\"\"Visualiza el espacio latente\"\"\"\n",
        "    from sklearn.decomposition import PCA\n",
        "\n",
        "    # Aplicar PCA si es necesario\n",
        "    if latent_space.shape[1] > 2:\n",
        "        pca = PCA(n_components=2)\n",
        "        latent_space_2d = pca.fit_transform(latent_space)\n",
        "    else:\n",
        "        latent_space_2d = latent_space\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    unique_labels = np.unique(labels)\n",
        "    colors = plt.cm.rainbow(np.linspace(0, 1, len(unique_labels)))\n",
        "\n",
        "    for label, color in zip(unique_labels, colors):\n",
        "        mask = labels == label\n",
        "        plt.scatter(latent_space_2d[mask, 0],\n",
        "                   latent_space_2d[mask, 1],\n",
        "                   c=[color],\n",
        "                   label=label_encoder.inverse_transform([label])[0],\n",
        "                   alpha=0.6)\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Primera Componente')\n",
        "    plt.ylabel('Segunda Componente')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "def plot_results_comparison(results):\n",
        "    \"\"\"Visualiza comparación de resultados\"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Preparar datos para el gráfico\n",
        "    models = []\n",
        "    accuracies = []\n",
        "    dims = []\n",
        "\n",
        "    for result in results:\n",
        "        models.append(result['model_type'])\n",
        "        accuracies.append(result['accuracy'])\n",
        "        dims.append(str(result['params']['encoding_dim']))\n",
        "\n",
        "    df_results = pd.DataFrame({\n",
        "        'Model Type': models,\n",
        "        'Accuracy': accuracies,\n",
        "        'Encoding Dim': dims\n",
        "    })\n",
        "\n",
        "    sns.barplot(x='Encoding Dim', y='Accuracy', hue='Model Type', data=df_results)\n",
        "    plt.title('Comparison of Model Configurations')\n",
        "    plt.ylabel('Test Accuracy')\n",
        "    plt.show()\n",
        "\n",
        "def get_encoder_model(autoencoder):\n",
        "    \"\"\"Extrae el modelo del encoder del autoencoder\"\"\"\n",
        "    # Crear un modelo que solo incluye hasta la capa del encoder\n",
        "    encoder = Model(inputs=autoencoder.input,\n",
        "                    outputs=autoencoder.get_layer('encoder_output').output)\n",
        "    return encoder"
      ],
      "metadata": {
        "id": "brdqq0KVFv9G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Configuración de parámetros\n",
        "param_combinations = [\n",
        "    {'encoding_dim': 32, 'sparsity': 1e-5, 'dropout_rate': 0.1},\n",
        "    {'encoding_dim': 64, 'sparsity': 1e-6, 'dropout_rate': 0.2},\n",
        "    {'encoding_dim': 128, 'sparsity': 1e-7, 'dropout_rate': 0.3}\n",
        "]\n",
        "\n",
        "# 1. Cargar y preprocesar datos\n",
        "train_df, test_df, label_encoder = load_and_preprocess_data(\n",
        "    'train.csv',\n",
        "    'test.csv'\n",
        ")\n",
        "\n",
        "# 2. Cargar imágenes\n",
        "X_train_images, y_train_labels, y_train_encoded = load_images_from_paths(train_df)\n",
        "X_test_images, y_test_labels, y_test_encoded = load_images_from_paths(test_df)\n",
        "\n",
        "# 3. Aplanar imágenes\n",
        "input_dim = X_train_images.shape[1] * X_train_images.shape[2]\n",
        "X_train_flat = X_train_images.reshape((X_train_images.shape[0], input_dim))\n",
        "X_test_flat = X_test_images.reshape((X_test_images.shape[0], input_dim))\n",
        "\n",
        "# 4. Almacenar resultados\n",
        "all_results = []\n",
        "\n",
        "# 5. Entrenar y evaluar modelos\n",
        "for params in param_combinations:\n",
        "    print(f\"\\nEvaluando configuración: {params}\")\n",
        "\n",
        "    # Sparse Autoencoder\n",
        "    print(\"\\nEntrenando Sparse Autoencoder...\")\n",
        "    sparse_ae = build_sparse_autoencoder(\n",
        "        input_dim=input_dim,\n",
        "        encoding_dim=params['encoding_dim'],\n",
        "        sparsity_reg=params['sparsity']\n",
        "    )\n",
        "\n",
        "    sparse_ae, sparse_history = train_autoencoder(\n",
        "        sparse_ae,\n",
        "        X_train_flat\n",
        "    )\n",
        "\n",
        "    sparse_latent_train = get_latent_space(sparse_ae, X_train_flat)\n",
        "    sparse_latent_test = get_latent_space(sparse_ae, X_test_flat)\n",
        "\n",
        "    sparse_results = train_and_evaluate_classifier(\n",
        "        sparse_latent_train,\n",
        "        sparse_latent_test,\n",
        "        y_train_encoded,\n",
        "        y_test_encoded\n",
        "    )\n",
        "\n",
        "    sparse_results.update({\n",
        "        'model_type': 'Sparse',\n",
        "        'params': params\n",
        "    })\n",
        "    all_results.append(sparse_results)\n",
        "\n",
        "    # Denoising Autoencoder\n",
        "    print(\"\\nEntrenando Denoising Autoencoder...\")\n",
        "    denoising_ae = build_denoising_autoencoder(\n",
        "        input_dim=input_dim,\n",
        "        encoding_dim=params['encoding_dim'],\n",
        "        dropout_rate=params['dropout_rate']\n",
        "    )\n",
        "\n",
        "    denoising_ae, denoising_history = train_autoencoder(\n",
        "        denoising_ae,\n",
        "        X_train_flat\n",
        "    )\n",
        "\n",
        "    denoising_latent_train = get_latent_space(denoising_ae, X_train_flat)\n",
        "    denoising_latent_test = get_latent_space(denoising_ae, X_test_flat)\n",
        "\n",
        "    denoising_results = train_and_evaluate_classifier(\n",
        "        denoising_latent_train,\n",
        "        denoising_latent_test,\n",
        "        y_train_encoded,\n",
        "        y_test_encoded\n",
        "    )\n",
        "\n",
        "    denoising_results.update({\n",
        "        'model_type': 'Denoising',\n",
        "        'params': params\n",
        "    })\n",
        "    all_results.append(denoising_results)\n",
        "\n",
        "# 6. Visualizar comparación final\n",
        "plot_results_comparison(all_results)\n",
        "\n",
        "# 7. Encontrar mejor configuración\n",
        "best_result = max(all_results, key=lambda x: x['accuracy'])\n",
        "print(\"\\nMejor configuración encontrada:\")\n",
        "print(f\"Tipo de modelo: {best_result['model_type']}\")\n",
        "print(f\"Parámetros: {best_result['params']}\")\n",
        "print(f\"Accuracy: {best_result['accuracy']:.4f}\")\n",
        "print(\"\\nReporte de clasificación detallado:\")\n",
        "print(classification_report(y_test_encoded, best_result['predictions']))"
      ],
      "metadata": {
        "id": "QS7ghDj8Eqe6",
        "outputId": "9a79ac5b-df48-44a7-8c74-b35de3d1bd37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluando configuración: {'encoding_dim': 32, 'sparsity': 1e-05, 'dropout_rate': 0.1}\n",
            "\n",
            "Entrenando Sparse Autoencoder...\n",
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - loss: 0.0647 - val_loss: 0.0627\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0644 - val_loss: 0.0624\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0630 - val_loss: 0.0620\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0634 - val_loss: 0.0617\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0613 - val_loss: 0.0614\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0615 - val_loss: 0.0610\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0613 - val_loss: 0.0607\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0605 - val_loss: 0.0604\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0613 - val_loss: 0.0601\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0599 - val_loss: 0.0597\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0614 - val_loss: 0.0594\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0600 - val_loss: 0.0591\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0604 - val_loss: 0.0588\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0579 - val_loss: 0.0584\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0591 - val_loss: 0.0581\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0593 - val_loss: 0.0578\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0586 - val_loss: 0.0575\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0578 - val_loss: 0.0572\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0573 - val_loss: 0.0569\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0563 - val_loss: 0.0566\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0568 - val_loss: 0.0563\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.0563 - val_loss: 0.0560\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0567 - val_loss: 0.0557\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0567 - val_loss: 0.0554\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0564 - val_loss: 0.0551\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0556 - val_loss: 0.0548\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0548 - val_loss: 0.0546\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0559 - val_loss: 0.0543\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0546 - val_loss: 0.0540\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0541 - val_loss: 0.0537\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0543 - val_loss: 0.0535\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0542 - val_loss: 0.0532\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0526 - val_loss: 0.0529\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0543 - val_loss: 0.0527\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0529 - val_loss: 0.0524\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0525 - val_loss: 0.0521\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0529 - val_loss: 0.0519\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0533 - val_loss: 0.0516\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0524 - val_loss: 0.0514\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0529 - val_loss: 0.0511\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0515 - val_loss: 0.0509\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0511 - val_loss: 0.0506\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0513 - val_loss: 0.0504\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0523 - val_loss: 0.0501\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0512 - val_loss: 0.0499\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0515 - val_loss: 0.0497\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0503 - val_loss: 0.0494\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0502 - val_loss: 0.0492\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0496 - val_loss: 0.0490\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0495 - val_loss: 0.0488\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0494 - val_loss: 0.0485\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0494 - val_loss: 0.0483\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0490 - val_loss: 0.0481\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0492 - val_loss: 0.0479\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0486 - val_loss: 0.0477\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0483 - val_loss: 0.0475\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0478 - val_loss: 0.0472\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0489 - val_loss: 0.0470\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0483 - val_loss: 0.0468\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0479 - val_loss: 0.0466\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0475 - val_loss: 0.0464\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0468 - val_loss: 0.0462\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0468 - val_loss: 0.0460\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0471 - val_loss: 0.0458\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0472 - val_loss: 0.0456\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0473 - val_loss: 0.0454\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0464 - val_loss: 0.0453\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0464 - val_loss: 0.0451\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0462 - val_loss: 0.0449\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0460 - val_loss: 0.0447\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0453 - val_loss: 0.0445\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0463 - val_loss: 0.0443\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0446 - val_loss: 0.0442\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0451 - val_loss: 0.0440\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0448 - val_loss: 0.0438\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0442 - val_loss: 0.0436\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0442 - val_loss: 0.0435\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0438 - val_loss: 0.0433\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0437 - val_loss: 0.0431\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0439 - val_loss: 0.0429\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0443 - val_loss: 0.0428\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0437 - val_loss: 0.0426\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0431 - val_loss: 0.0425\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0430 - val_loss: 0.0423\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0438 - val_loss: 0.0421\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0430 - val_loss: 0.0420\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0422 - val_loss: 0.0418\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0423 - val_loss: 0.0417\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0422 - val_loss: 0.0415\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0415 - val_loss: 0.0414\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0424 - val_loss: 0.0412\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0416 - val_loss: 0.0411\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0425 - val_loss: 0.0409\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0420 - val_loss: 0.0408\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0418 - val_loss: 0.0406\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0417 - val_loss: 0.0405\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0425 - val_loss: 0.0404\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0408 - val_loss: 0.0402\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0409 - val_loss: 0.0401\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0399 - val_loss: 0.0399\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "Entrenando Denoising Autoencoder...\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
            "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
            "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0618 - val_loss: 0.0497\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0453 - val_loss: 0.0304\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0302 - val_loss: 0.0264\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0264 - val_loss: 0.0247\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0254 - val_loss: 0.0237\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0242 - val_loss: 0.0234\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0240 - val_loss: 0.0227\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0245 - val_loss: 0.0221\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0230 - val_loss: 0.0213\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0222 - val_loss: 0.0206\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0217 - val_loss: 0.0198\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0193 - val_loss: 0.0192\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0188 - val_loss: 0.0185\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0179 - val_loss: 0.0175\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0168 - val_loss: 0.0169\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0165 - val_loss: 0.0161\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0152 - val_loss: 0.0156\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0151 - val_loss: 0.0155\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0147 - val_loss: 0.0153\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0140 - val_loss: 0.0153\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0140 - val_loss: 0.0150\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0134 - val_loss: 0.0143\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0126 - val_loss: 0.0141\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0129 - val_loss: 0.0138\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0120 - val_loss: 0.0136\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0122 - val_loss: 0.0135\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0120 - val_loss: 0.0136\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0113 - val_loss: 0.0132\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0112 - val_loss: 0.0127\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0107 - val_loss: 0.0125\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0113 - val_loss: 0.0126\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0106 - val_loss: 0.0124\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0102 - val_loss: 0.0124\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0104 - val_loss: 0.0122\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0104 - val_loss: 0.0122\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0103 - val_loss: 0.0119\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0102 - val_loss: 0.0119\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0098 - val_loss: 0.0118\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0097 - val_loss: 0.0116\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0100 - val_loss: 0.0116\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0100 - val_loss: 0.0114\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0097 - val_loss: 0.0114\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0096 - val_loss: 0.0113\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0094 - val_loss: 0.0112\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0092 - val_loss: 0.0111\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0090 - val_loss: 0.0108\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0088 - val_loss: 0.0107\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0089 - val_loss: 0.0106\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0086 - val_loss: 0.0105\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0085 - val_loss: 0.0103\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0084 - val_loss: 0.0103\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0086 - val_loss: 0.0103\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0086 - val_loss: 0.0103\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0082 - val_loss: 0.0101\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0081 - val_loss: 0.0099\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0081 - val_loss: 0.0099\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0081 - val_loss: 0.0099\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0077 - val_loss: 0.0099\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0079 - val_loss: 0.0101\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0080 - val_loss: 0.0099\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0082 - val_loss: 0.0098\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0078 - val_loss: 0.0096\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0076 - val_loss: 0.0096\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0076 - val_loss: 0.0096\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0075 - val_loss: 0.0097\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0077 - val_loss: 0.0097\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0076 - val_loss: 0.0095\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0074 - val_loss: 0.0095\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0074 - val_loss: 0.0095\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0075 - val_loss: 0.0097\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0076 - val_loss: 0.0095\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0073 - val_loss: 0.0094\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0073 - val_loss: 0.0094\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0073 - val_loss: 0.0094\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0077 - val_loss: 0.0096\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0075 - val_loss: 0.0095\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0075 - val_loss: 0.0095\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0070 - val_loss: 0.0094\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79d8800f29e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 16 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79d873707760> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\n",
            "Evaluando configuración: {'encoding_dim': 64, 'sparsity': 1e-06, 'dropout_rate': 0.2}\n",
            "\n",
            "Entrenando Sparse Autoencoder...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - loss: 0.0635 - val_loss: 0.0627\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0636 - val_loss: 0.0624\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0626 - val_loss: 0.0620\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0624 - val_loss: 0.0617\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0622 - val_loss: 0.0614\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0614 - val_loss: 0.0610\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0623 - val_loss: 0.0607\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0615 - val_loss: 0.0604\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0618 - val_loss: 0.0601\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0619 - val_loss: 0.0597\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0597 - val_loss: 0.0594\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0594 - val_loss: 0.0591\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0611 - val_loss: 0.0588\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0592 - val_loss: 0.0584\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0603 - val_loss: 0.0581\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0605 - val_loss: 0.0578\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0576 - val_loss: 0.0575\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0582 - val_loss: 0.0572\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0576 - val_loss: 0.0569\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0581 - val_loss: 0.0566\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0572 - val_loss: 0.0563\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0572 - val_loss: 0.0560\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0580 - val_loss: 0.0557\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0566 - val_loss: 0.0554\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0553 - val_loss: 0.0551\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0560 - val_loss: 0.0548\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0549 - val_loss: 0.0546\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0553 - val_loss: 0.0543\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0543 - val_loss: 0.0540\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0553 - val_loss: 0.0537\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0545 - val_loss: 0.0535\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0535 - val_loss: 0.0532\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0548 - val_loss: 0.0529\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0545 - val_loss: 0.0527\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0537 - val_loss: 0.0524\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0526 - val_loss: 0.0521\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0527 - val_loss: 0.0519\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0525 - val_loss: 0.0516\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0520 - val_loss: 0.0514\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0526 - val_loss: 0.0511\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0515 - val_loss: 0.0509\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0529 - val_loss: 0.0506\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0521 - val_loss: 0.0504\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0504 - val_loss: 0.0502\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0500 - val_loss: 0.0499\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0513 - val_loss: 0.0497\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0509 - val_loss: 0.0494\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0496 - val_loss: 0.0492\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0505 - val_loss: 0.0490\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0497 - val_loss: 0.0488\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0496 - val_loss: 0.0485\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0496 - val_loss: 0.0483\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0494 - val_loss: 0.0481\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0481 - val_loss: 0.0479\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0483 - val_loss: 0.0477\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0489 - val_loss: 0.0475\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0491 - val_loss: 0.0472\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0490 - val_loss: 0.0470\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0485 - val_loss: 0.0468\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0478 - val_loss: 0.0466\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0477 - val_loss: 0.0464\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0474 - val_loss: 0.0462\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0459 - val_loss: 0.0460\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0457 - val_loss: 0.0458\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0468 - val_loss: 0.0456\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0468 - val_loss: 0.0454\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0458 - val_loss: 0.0453\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0467 - val_loss: 0.0451\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0463 - val_loss: 0.0449\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0455 - val_loss: 0.0447\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0454 - val_loss: 0.0445\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0461 - val_loss: 0.0443\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0453 - val_loss: 0.0442\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0454 - val_loss: 0.0440\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0461 - val_loss: 0.0438\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0435 - val_loss: 0.0436\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0445 - val_loss: 0.0435\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0446 - val_loss: 0.0433\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0431 - val_loss: 0.0431\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0445 - val_loss: 0.0430\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0430 - val_loss: 0.0428\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0437 - val_loss: 0.0426\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0433 - val_loss: 0.0425\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0431 - val_loss: 0.0423\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0433 - val_loss: 0.0421\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0426 - val_loss: 0.0420\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0424 - val_loss: 0.0418\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0430 - val_loss: 0.0417\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - loss: 0.0427 - val_loss: 0.0415\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0431 - val_loss: 0.0414\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.0418 - val_loss: 0.0412\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0416 - val_loss: 0.0411\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0424 - val_loss: 0.0409\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0423 - val_loss: 0.0408\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0415 - val_loss: 0.0406\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0419 - val_loss: 0.0405\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0418 - val_loss: 0.0404\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0400 - val_loss: 0.0402\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0410 - val_loss: 0.0401\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0400 - val_loss: 0.0399\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\n",
            "Entrenando Denoising Autoencoder...\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
            "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
            "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0620 - val_loss: 0.0481\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0447 - val_loss: 0.0286\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0288 - val_loss: 0.0261\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0264 - val_loss: 0.0244\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0253 - val_loss: 0.0235\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0244 - val_loss: 0.0227\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0235 - val_loss: 0.0217\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0226 - val_loss: 0.0207\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0212 - val_loss: 0.0198\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0196 - val_loss: 0.0188\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0192 - val_loss: 0.0182\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0175 - val_loss: 0.0175\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0164 - val_loss: 0.0170\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0157 - val_loss: 0.0166\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0149 - val_loss: 0.0155\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0139 - val_loss: 0.0147\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0128 - val_loss: 0.0141\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0121 - val_loss: 0.0136\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0116 - val_loss: 0.0132\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0116 - val_loss: 0.0130\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0113 - val_loss: 0.0126\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0112 - val_loss: 0.0124\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0104 - val_loss: 0.0122\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0104 - val_loss: 0.0123\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0107 - val_loss: 0.0119\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0102 - val_loss: 0.0118\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0101 - val_loss: 0.0114\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0100 - val_loss: 0.0118\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0101 - val_loss: 0.0114\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0095 - val_loss: 0.0112\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0094 - val_loss: 0.0110\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0094 - val_loss: 0.0109\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0092 - val_loss: 0.0107\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0090 - val_loss: 0.0105\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0088 - val_loss: 0.0105\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0086 - val_loss: 0.0104\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0085 - val_loss: 0.0102\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0083 - val_loss: 0.0102\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0083 - val_loss: 0.0103\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0082 - val_loss: 0.0102\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0083 - val_loss: 0.0099\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0078 - val_loss: 0.0101\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0078 - val_loss: 0.0100\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0081 - val_loss: 0.0100\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0078 - val_loss: 0.0096\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0078 - val_loss: 0.0097\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0077 - val_loss: 0.0095\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0077 - val_loss: 0.0096\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0079 - val_loss: 0.0095\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0075 - val_loss: 0.0095\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0073 - val_loss: 0.0095\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0072 - val_loss: 0.0095\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0073 - val_loss: 0.0094\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0072 - val_loss: 0.0093\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0071 - val_loss: 0.0092\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0072 - val_loss: 0.0093\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0071 - val_loss: 0.0092\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0070 - val_loss: 0.0091\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0070 - val_loss: 0.0092\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0071 - val_loss: 0.0091\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0069 - val_loss: 0.0091\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0067 - val_loss: 0.0090\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0068 - val_loss: 0.0090\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0067 - val_loss: 0.0092\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0066 - val_loss: 0.0089\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0066 - val_loss: 0.0088\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0067 - val_loss: 0.0089\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0063 - val_loss: 0.0090\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - loss: 0.0065 - val_loss: 0.0089\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0065 - val_loss: 0.0088\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0066 - val_loss: 0.0089\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\n",
            "Evaluando configuración: {'encoding_dim': 128, 'sparsity': 1e-07, 'dropout_rate': 0.3}\n",
            "\n",
            "Entrenando Sparse Autoencoder...\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0621 - val_loss: 0.0439\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0395 - val_loss: 0.0281\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0288 - val_loss: 0.0260\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0268 - val_loss: 0.0245\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0261 - val_loss: 0.0239\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0244 - val_loss: 0.0233\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0247 - val_loss: 0.0227\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0233 - val_loss: 0.0221\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0227 - val_loss: 0.0214\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0219 - val_loss: 0.0202\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0204 - val_loss: 0.0188\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0183 - val_loss: 0.0176\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0172 - val_loss: 0.0166\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0161 - val_loss: 0.0162\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0151 - val_loss: 0.0155\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0139 - val_loss: 0.0152\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0138 - val_loss: 0.0141\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0128 - val_loss: 0.0136\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0121 - val_loss: 0.0134\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0120 - val_loss: 0.0133\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0113 - val_loss: 0.0130\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0111 - val_loss: 0.0128\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0113 - val_loss: 0.0129\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0110 - val_loss: 0.0126\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0105 - val_loss: 0.0124\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0105 - val_loss: 0.0121\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0104 - val_loss: 0.0120\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0103 - val_loss: 0.0118\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0098 - val_loss: 0.0117\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0097 - val_loss: 0.0115\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0094 - val_loss: 0.0115\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0095 - val_loss: 0.0114\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0092 - val_loss: 0.0114\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0092 - val_loss: 0.0113\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0088 - val_loss: 0.0112\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0087 - val_loss: 0.0110\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0087 - val_loss: 0.0107\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0088 - val_loss: 0.0108\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0086 - val_loss: 0.0105\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0082 - val_loss: 0.0104\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0084 - val_loss: 0.0104\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0081 - val_loss: 0.0104\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0083 - val_loss: 0.0101\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0078 - val_loss: 0.0101\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0077 - val_loss: 0.0101\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0078 - val_loss: 0.0103\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0079 - val_loss: 0.0102\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0076 - val_loss: 0.0098\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0077 - val_loss: 0.0098\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0076 - val_loss: 0.0098\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0074 - val_loss: 0.0098\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0072 - val_loss: 0.0097\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0074 - val_loss: 0.0096\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0074 - val_loss: 0.0096\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0072 - val_loss: 0.0096\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0070 - val_loss: 0.0096\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0072 - val_loss: 0.0095\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0070 - val_loss: 0.0095\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0071 - val_loss: 0.0094\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0071 - val_loss: 0.0094\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0069 - val_loss: 0.0097\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0068 - val_loss: 0.0093\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0067 - val_loss: 0.0093\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0066 - val_loss: 0.0095\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0065 - val_loss: 0.0092\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0065 - val_loss: 0.0093\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0066 - val_loss: 0.0092\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0066 - val_loss: 0.0093\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0064 - val_loss: 0.0092\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0063 - val_loss: 0.0091\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0064 - val_loss: 0.0092\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0061 - val_loss: 0.0092\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0061 - val_loss: 0.0091\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0062 - val_loss: 0.0092\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0061 - val_loss: 0.0090\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0061 - val_loss: 0.0090\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0061 - val_loss: 0.0090\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0062 - val_loss: 0.0089\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0060 - val_loss: 0.0091\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0061 - val_loss: 0.0089\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0060 - val_loss: 0.0089\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0060 - val_loss: 0.0089\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0060 - val_loss: 0.0089\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0056 - val_loss: 0.0088\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0059 - val_loss: 0.0088\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0059 - val_loss: 0.0088\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0059 - val_loss: 0.0088\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0058 - val_loss: 0.0088\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0060 - val_loss: 0.0088\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0058 - val_loss: 0.0087\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0058 - val_loss: 0.0087\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0057 - val_loss: 0.0087\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0056 - val_loss: 0.0087\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0057 - val_loss: 0.0086\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0055 - val_loss: 0.0088\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0057 - val_loss: 0.0086\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0057 - val_loss: 0.0088\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0057 - val_loss: 0.0086\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0056 - val_loss: 0.0088\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0056 - val_loss: 0.0085\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\n",
            "Entrenando Denoising Autoencoder...\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0612 - val_loss: 0.0363\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0332 - val_loss: 0.0270\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0276 - val_loss: 0.0248\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0267 - val_loss: 0.0237\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0239 - val_loss: 0.0228\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0241 - val_loss: 0.0217\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0221 - val_loss: 0.0203\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0200 - val_loss: 0.0189\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0196 - val_loss: 0.0177\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0170 - val_loss: 0.0166\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0160 - val_loss: 0.0158\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0143 - val_loss: 0.0149\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0135 - val_loss: 0.0140\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0129 - val_loss: 0.0135\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0120 - val_loss: 0.0133\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0112 - val_loss: 0.0125\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0109 - val_loss: 0.0129\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0108 - val_loss: 0.0120\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0103 - val_loss: 0.0119\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0101 - val_loss: 0.0114\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0096 - val_loss: 0.0116\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0095 - val_loss: 0.0109\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0093 - val_loss: 0.0106\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0088 - val_loss: 0.0103\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0086 - val_loss: 0.0104\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0082 - val_loss: 0.0100\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0082 - val_loss: 0.0098\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0079 - val_loss: 0.0098\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0078 - val_loss: 0.0096\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0076 - val_loss: 0.0094\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0074 - val_loss: 0.0093\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0077 - val_loss: 0.0093\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0072 - val_loss: 0.0093\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0077 - val_loss: 0.0091\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0073 - val_loss: 0.0094\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0072 - val_loss: 0.0090\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0070 - val_loss: 0.0089\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0066 - val_loss: 0.0088\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0066 - val_loss: 0.0088\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0065 - val_loss: 0.0086\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0064 - val_loss: 0.0087\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0065 - val_loss: 0.0089\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0064 - val_loss: 0.0087\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0062 - val_loss: 0.0085\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0062 - val_loss: 0.0084\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0062 - val_loss: 0.0084\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0059 - val_loss: 0.0084\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0060 - val_loss: 0.0086\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - loss: 0.0060 - val_loss: 0.0083\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0060 - val_loss: 0.0082\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 243ms/step - loss: 0.0058 - val_loss: 0.0081\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step - loss: 0.0057 - val_loss: 0.0082\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0056 - val_loss: 0.0083\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0056 - val_loss: 0.0081\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0055 - val_loss: 0.0081\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0055 - val_loss: 0.0081\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0055 - val_loss: 0.0080\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0055 - val_loss: 0.0081\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0053 - val_loss: 0.0080\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0051 - val_loss: 0.0079\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0053 - val_loss: 0.0078\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - loss: 0.0052 - val_loss: 0.0078\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 160ms/step - loss: 0.0051 - val_loss: 0.0077\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 233ms/step - loss: 0.0051 - val_loss: 0.0077\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - loss: 0.0049 - val_loss: 0.0077\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - loss: 0.0049 - val_loss: 0.0077\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0050 - val_loss: 0.0077\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.0049 - val_loss: 0.0075\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0048 - val_loss: 0.0075\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0048 - val_loss: 0.0079\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0049 - val_loss: 0.0075\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0049 - val_loss: 0.0074\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0047 - val_loss: 0.0075\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0047 - val_loss: 0.0074\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0046 - val_loss: 0.0074\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0047 - val_loss: 0.0073\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0046 - val_loss: 0.0074\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0046 - val_loss: 0.0073\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0046 - val_loss: 0.0073\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0046 - val_loss: 0.0075\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0045 - val_loss: 0.0074\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0045 - val_loss: 0.0072\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0046 - val_loss: 0.0072\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0045 - val_loss: 0.0073\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0044 - val_loss: 0.0073\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0045 - val_loss: 0.0072\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0044 - val_loss: 0.0073\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0043 - val_loss: 0.0071\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0043 - val_loss: 0.0072\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0041 - val_loss: 0.0073\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0044 - val_loss: 0.0071\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0043 - val_loss: 0.0071\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0043 - val_loss: 0.0072\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0042 - val_loss: 0.0071\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0042 - val_loss: 0.0074\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0042 - val_loss: 0.0073\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mejor configuración encontrada:\n",
            "Tipo de modelo: Sparse\n",
            "Parámetros: {'encoding_dim': 32, 'sparsity': 1e-05, 'dropout_rate': 0.1}\n",
            "Accuracy: 0.4167\n",
            "\n",
            "Reporte de clasificación detallado:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      1.00      0.59         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.42        12\n",
            "   macro avg       0.10      0.25      0.15        12\n",
            "weighted avg       0.17      0.42      0.25        12\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar resultados para todas las configuraciones\n",
        "print(\"\\nResultados para todas las configuraciones:\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for result in all_results:\n",
        "    print(f\"\\nTipo de modelo: {result['model_type']}\")\n",
        "    print(f\"Parámetros:\")\n",
        "    print(f\"  - Dimensión de codificación: {result['params']['encoding_dim']}\")\n",
        "    if result['model_type'] == 'Sparse':\n",
        "        print(f\"  - Regularización de sparsity: {result['params']['sparsity']}\")\n",
        "    else:\n",
        "        print(f\"  - Tasa de dropout: {result['params']['dropout_rate']}\")\n",
        "    print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "id": "wjdygzjeJTsO",
        "outputId": "0c4dceef-0674-49c2-cbf6-b90719bc4367",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Resultados para todas las configuraciones:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Tipo de modelo: Sparse\n",
            "Parámetros:\n",
            "  - Dimensión de codificación: 32\n",
            "  - Regularización de sparsity: 1e-05\n",
            "Accuracy: 0.4167\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Tipo de modelo: Denoising\n",
            "Parámetros:\n",
            "  - Dimensión de codificación: 32\n",
            "  - Tasa de dropout: 0.1\n",
            "Accuracy: 0.2500\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Tipo de modelo: Sparse\n",
            "Parámetros:\n",
            "  - Dimensión de codificación: 64\n",
            "  - Regularización de sparsity: 1e-06\n",
            "Accuracy: 0.4167\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Tipo de modelo: Denoising\n",
            "Parámetros:\n",
            "  - Dimensión de codificación: 64\n",
            "  - Tasa de dropout: 0.2\n",
            "Accuracy: 0.0833\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Tipo de modelo: Sparse\n",
            "Parámetros:\n",
            "  - Dimensión de codificación: 128\n",
            "  - Regularización de sparsity: 1e-07\n",
            "Accuracy: 0.1667\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Tipo de modelo: Denoising\n",
            "Parámetros:\n",
            "  - Dimensión de codificación: 128\n",
            "  - Tasa de dropout: 0.3\n",
            "Accuracy: 0.1667\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}